{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project name - Housing Price Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitted To -Appwars  Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitted by Group -3 Members\n",
    "\n",
    "Sushmita Ramdham                                                                                                               \n",
    "Yash Mittal\n",
    "Tanya Yadav                                                                                                                     \n",
    "Aman Thakur\n",
    "Brajsundari Rathore                                                                                                             \n",
    "Jai Gupta                                                                                                                       \n",
    "Nikhil Nair                                                                                                                     \n",
    "Priya Pal                                                                                                                       \n",
    "Saima Siddiqui                                                                                                                 \n",
    "Sameer Anand  \n",
    "Aashish Kumar pandey \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About project\n",
    "In this project, we will develop and evaluate a model trained and tested on data collected for housing price prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as smfa\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Pandas' is a library written for the Python programming language for data manipulation and analysis. It is most widely used for data science,data analysis and machine learning work ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib is a python  library used for data visualization in different forms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Sklearn'also known as 'scikit-learn' is a software machine learning library for the Python programming language which features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.\n",
    "#### Regression algorithm in Sklearn\n",
    "It is used to predict a continuous-valued attribute associated with an object(predictor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statsmodels is a Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration.\n",
    "\n",
    "#### statsmodels.api\n",
    "Cross-sectional models and methods. (Cross-sectional analysis looks at data collected at a single point in time, rather than over a period of time.)\n",
    "#### statsmodels.formula.api\n",
    "A convenience interface for specifying models using formula strings and DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seaborn\n",
    "Seaborn is a library in Python predominantly used for making statistical graphics. Seaborn is a data visualization library built on top of matplotlib and closely integrated with pandas data structures in Python. Visualization is the central part of Seaborn which helps in exploration and understanding of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting data through 'Pandas' Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"D:/MCA/market_data/Housing Price Prediction .csv\")\n",
    "# Here we are getting our data of 'Housing Price Prediction' through pd.read_csv(file_name.extension) and \n",
    "#assigning to 'data' variable . \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Data:\n",
    "The dataset used in this project comes from  Machine Learning Repository Appwars Technology. which is in csv(comma separated value) format. It contains 21597 rows also known as observation and 21 columns also known as features. Our aim is to predict the price of house based on the features which have major role in predicting price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(20)\n",
    "# Dataframe.head() tells us the topmost 5 values of the data as it's default in it we can change it by passing value in head..\n",
    "# For example \n",
    "# data.head(20)\n",
    "# It tells us topmost 20 value of the dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "# .shape tells us the shape (number of rows, number of columns) of the dataset..\n",
    "# Our dataset (Housing Price Predicton) has 21597 rows also known as observation and 21 columns also known as features... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())\n",
    "# It tells us about our dataset if any 'Null' value is present in it columnwise.\n",
    "# In our dataset there in no 'Null' value present in it.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "# .columns tells us about the all the columns aka features of the dataset.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n",
    "# .describe() tells us the about the complete statistics about the data. In our data it includes count, mean, standard deviation,\n",
    "# and percentiles of 'Housing price prediction'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes\n",
    "# checking data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"waterfront\",\"view\",\"id\",\"yr_renovated\",\"long\"],axis=1,inplace=True)\n",
    "# Here we are sorting our dataset by 'yr_built' in descending order to check our latest built houses..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\"lat\")[\"lat\"].count()\n",
    "#Grouping of data Acording to 'lat' and count that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"lat\"],axis=1,inplace=True)\n",
    "#drop 'lat' attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot(data[\"price\"])\n",
    "# checking outlier by boxplot in 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.boxplot(data[\"sqft_living\"])\n",
    "# checking outlier by boxplot in 'sqft_living'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding inter quantile value of 'price'\n",
    "p_q1,p_q3=data['price'].quantile([.25,.75])\n",
    "p_iqr=p_q3-p_q1\n",
    "p_ll=p_q1-1.5*(p_iqr)\n",
    "p_ul=p_q3+1.5*(p_iqr)\n",
    "print(p_ll,p_ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding inter quantile value of 'sqft_living'\n",
    "s_q1,s_q3=data['sqft_living'].quantile([.25,.75])\n",
    "s_iqr=s_q3-s_q1\n",
    "s_ll=s_q1-1.5*(s_iqr)\n",
    "s_ul=s_q3+1.5*(s_iqr)\n",
    "print(s_ll,s_ul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['price']>p_ul].count()\n",
    "#counting value of price greater than upper limit of price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['sqft_living']>s_ul]=s_ul\n",
    "data[data['price']>p_ul]=p_ul\n",
    "#removeing outlier of 'sqft_living' & 'price' upper limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.boxplot(data[\"price\"] ,labels=['price'])\n",
    "#box plot after removing outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.boxplot(data['sqft_living'] ,labels=['sqft_living'])\n",
    "plt.ylim(0,10000)\n",
    "#box plot after removing outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['price'],ascending=False,inplace=True)\n",
    "#shorting of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bathrooms'] = data['bathrooms'].astype('int64')\n",
    "\n",
    "data['floors'] = data['floors'].astype('int64')\n",
    "#changing dtat type of 'bathrooms'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()\n",
    "# corr() is used to find the pairwise correlation of all columns in the dataframe. \n",
    "# Any na values are automatically excluded. For any non-numeric data type columns in the dataframe it is ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of data (Housing Price Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(17,11)})\n",
    "sns.heatmap(data.corr(), annot = True, cmap = 'magma')\n",
    "# Heatmap is defined as a graphical representation of data using colors to visualize the value of the matrix. \n",
    "# In this, to represent more common values or higher activities brighter colors basically reddish colors are used and \n",
    "# to represent less common or activity values, darker colors are preferred. Heatmap is also defined by the name of the shading matrix.\n",
    "# Heatmaps in Seaborn can be plotted by using the seaborn.heatmap() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.distplot(data.loc[:,'price'])\n",
    "# distplot() function is used to plot the distplot. The distplot represents the univariate distribution of data \n",
    "# i.e. data distribution of a variable against the density distribution. \n",
    "# The seaborn. distplot() function accepts the data variable as an argument and returns the plot with the density distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model through Sklearn's linear_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting useful data and dividing them in dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=data.loc[:,[\"bedrooms\",\"bathrooms\",\"sqft_living\",\"grade\",\"yr_built\",\"zipcode\"]] # independent variables (all columns or features except 'price','date' & 'id' )\n",
    "y=data['price'] # dependent variable (it includes'price' column which we have to predict with our independent variables. )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing train_test_split\n",
    "It is a function in Sklearn model selection for splitting data arrays into two subsets: for training data and for testing data. With this function, you don't need to divide the dataset manually. By default, Sklearn train_test_split will make random partitions for the two subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "# Here train_x,train_y are training data with 0.7(or 70%) size and test_x,test_y are included in test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model from 'sklearn's linear_model' library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegression()\n",
    "\n",
    "## 'LinearRegression' fits a linear model with coefficients to minimize the residual sum of squares between the\n",
    "# observed targets in the dataset, and the targets predicted by the linear approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting variables to the above built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting through the above built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(test_x)\n",
    "# we have assigned our all prediction of test data in y_pred variable.\n",
    "pd.Series(y_pred)\n",
    "# to convert our array into pandas series..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing 'sklearn's mean_squared_error' library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.metrics\n",
    "The 'sklearn.metrics' module implements several loss, score, and utility functions to measure classification performance. Some metrics might require probability estimates of the positive class, confidence values, or binary decisions values.\n",
    "\n",
    "#### mean_squared_error\n",
    "'mean_squared_error' function computes mean square error, a risk metric corresponding to the expected value of the squared (quadratic) error or loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(test_y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model through 'statsmodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0=smfa.ols('price ~ sqft_living+date+yr_built+zipcode',data=data).fit()\n",
    "model0.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=smfa.ols('price ~ sqft_living',data=data).fit()\n",
    "# building our model thought statsmodel.formula.api's ordinary least squares(ols) only on basis of feature 'sqft_living' and\n",
    "# fitting it to our data\n",
    "model1.summary()\n",
    "# to show all the details about above built model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=smfa.ols('price ~ sqft_living+grade+sqft_above+sqft_living15+bathrooms',data=data).fit()\n",
    "# building our model thought statsmodel.formula.api's ordinary least squares(ols) only on basis of feature 'sqft_living' and\n",
    "# fitting it to our data\n",
    "model2.summary()\n",
    "# to show all the details about above built model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=smfa.ols('price ~ sqft_living+grade+sqft_above+sqft_living15+bathrooms+sqft_basement+bedrooms',data=data).fit()\n",
    "# building our model thought statsmodel.formula.api's ordinary least squares(ols) only on basis of feature 'sqft_living' and\n",
    "# fitting it to our data\n",
    "model3.summary()\n",
    "# to show all the details about above built model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6=smfa.ols('price ~ sqft_living+bathrooms+yr_built+bedrooms+grade+floors+condition',data=data).fit()\n",
    "# building our model thought statsmodel.formula.api's ordinary least squares(ols) only on basis of feature 'sqft_living' and\n",
    "# fitting it to our data\n",
    "model6.summary()\n",
    "# to show all the details about above built model.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilinear regression on sample of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.sample(100)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7=smfa.ols('price ~ sqft_living+bathrooms+yr_built+bedrooms+grade+floors+condition',data=data1).fit()\n",
    "# building our model thought statsmodel.formula.api's ordinary least squares(ols) only on basis of feature 'sqft_living' and\n",
    "# fitting it to our data\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing 'plotly' library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotly\n",
    "Plotly Express is the easy-to-use, high-level interface to Plotly, which operates on a variety of types of data and produces easy-to-style figures.Plotly Express provides functions to visualize a variety of types of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of individual feature's regression model with price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1=sns.regplot(x=data['sqft_living'], y=data[\"price\"], color=\"green\", marker='+')\n",
    "#fig1.set_xlim(0, 10000)\n",
    "# running a for loop for item in list 'variable' and visualise scattering of these features and their regression line using \n",
    "# plotly.express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1=sns.regplot(x=data['yr_built'], y=data[\"price\"], color=\"green\", marker='+')\n",
    "fig1.set_xlim(1900, 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1=sns.regplot(x=data['bathrooms'], y=data[\"price\"], color=\"green\", marker='+')\n",
    "fig1.set_xlim(0, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1=sns.regplot(x=data['bedrooms'], y=data[\"price\"], color=\"green\", marker='+')\n",
    "fig1.set_xlim(0, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1=sns.regplot(x=data['grade'], y=data[\"price\"], color=\"green\", marker='+')\n",
    "fig1.set_xlim(2, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1=sns.regplot(x=data['floors'], y=data[\"price\"], color=\"green\", marker='+')\n",
    "fig1.set_xlim(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1=sns.regplot(x=data['zipcode'], y=data[\"price\"], color=\"green\", marker='+')\n",
    "fig1.set_xlim(98000,98200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiliner visulisation with price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable=['sqft_living','bathrooms','yr_built','bedrooms','grade','floors','condition','zipcode']\n",
    "#creating a list of feature named variable \n",
    "colour=['red','green','magenta','blue','yellow','gray','brown','black']\n",
    "#creating a list of colours  named colour\n",
    "for i in range(0,len(variable)):\n",
    "    fig3=sns.regplot(x=data[variable[i]], y=data[\"price\"], color=colour[i], marker='+')\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiliner visulisation with predicted price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable=[\"bedrooms\",\"bathrooms\",\"sqft_living\",\"grade\",\"yr_built\",\"zipcode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data[variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=smfa.ols('price ~sqft_living',data=data).fit()\n",
    "data2['PRICE_AC_SQFT_LIVING']=m1.predict()\n",
    "# building regression model using feature 'sqft_living' and assigning its prediction to a column of dataframe 'data2'\n",
    "\n",
    "m3=smfa.ols('price ~bathrooms',data=data).fit()\n",
    "data2['PRICE_AC_BATHROOMS']=m3.predict()\n",
    "# building regression model using feature 'bathrooms' and assigning its prediction to a column of dataframe 'data2'\n",
    "\n",
    "m4=smfa.ols('price ~yr_built',data=data).fit()\n",
    "data2['PRICE_AC_YR_BUILT']=m4.predict()\n",
    "# building regression model using feature 'yr_built' and assigning its prediction to a column of dataframe 'data2'\n",
    "\n",
    "m5=smfa.ols('price ~bedrooms',data=data).fit()\n",
    "data2['PRICE_AC_BEDROOMS']=m5.predict()\n",
    "# building regression model using feature 'bedrooms' and assigning its prediction to a column of dataframe 'data2'\n",
    "\n",
    "m6=smfa.ols('price ~grade',data=data).fit()\n",
    "data2['PRICE_AC_GRADE']=m6.predict()\n",
    "# building regression model using feature 'grade' and assigning its prediction to a column of dataframe 'data2'\n",
    "\n",
    "m7=smfa.ols('price ~zipcode',data=data).fit()\n",
    "data2['PRICE_AC_ZIPCODE']=m7.predict()\n",
    "# building regression model using feature 'zipcode' and assigning its prediction to a column of dataframe 'data2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.scatter(data.bathrooms,data.price,c='#548CA8',label='bathrooms')\n",
    "plt.plot(data.bathrooms,data2.PRICE_AC_BATHROOMS,c='black',label='bathrooms regression')\n",
    "# scattering of observations of 'bathrooms' feature and plotting the prediction of model with respect to it\n",
    "\n",
    "plt.scatter(data.bedrooms,data.price,c='#C6B4CE',label='bedrooms')\n",
    "plt.plot(data.bedrooms,data2.PRICE_AC_BEDROOMS,c='#9B72AA',label='bedrooms regression')\n",
    "# scattering of observations of 'bedrooms' feature and plotting the prediction of model with respect to it\n",
    "\n",
    "\n",
    "plt.scatter(data.sqft_living,data.price,c='#A2DBFA',label='floors')\n",
    "plt.plot(data.sqft_living,data2.PRICE_AC_SQFT_LIVING,c='#39A2DB',label='floors regression')\n",
    "# scattering of observations of 'floors' feature and plotting the prediction of model with respect to it\n",
    "\n",
    "plt.scatter(data.yr_built,data.price,c='#47597E',label='view')\n",
    "plt.plot(data.yr_built,data2.PRICE_AC_YR_BUILT,c='#293B5F',label='view regression')\n",
    "# scattering of observations of 'view' feature and plotting the prediction of model with respect to it\n",
    "\n",
    "plt.scatter(data.zipcode,data.price,c='#5E8B7E',label='condition')\n",
    "plt.plot(data.zipcode,data2.PRICE_AC_ZIPCODE,c='#2F5D62',label='condition regeression')\n",
    "# scattering of observations of 'condition' feature and plotting the prediction of model with respect to it\n",
    "\n",
    "plt.title(\"Regression of various features with price\",fontsize = 30)\n",
    "# for assigning a title to vsualisation\n",
    "\n",
    "plt.ylabel(\"Prediction of houses\",fontsize=20)\n",
    "# for assigning a label of y-axis\n",
    "\n",
    "plt.xlabel(\"Frequency of various features\",fontsize=20)\n",
    "# for assigning a label of x-axis\n",
    "\n",
    "plt.legend([\"bedrooms\",\"bathrooms\",\"sqft_living\",\"yr_built\",\"zipcode\"])\n",
    "\n",
    "plt.xlim(0,5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction of price According to user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f89b5181277d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please Enter correct \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" -> \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0muser_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_x' is not defined"
     ]
    }
   ],
   "source": [
    "d=dict()\n",
    "for i in test_x.columns:\n",
    "    n=int(input(\"Please Enter correct \"+i+\" -> \"))\n",
    "    d[i]=n\n",
    "user_data=pd.DataFrame(d,index=[0])\n",
    "\n",
    "y_price_pred=model.predict(user_data)\n",
    "print(\"\\n Price of your house is nearly \")\n",
    "abs(int(y_price_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
